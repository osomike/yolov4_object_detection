{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tf2_yolov4.anchors import YOLOV4_ANCHORS\n",
    "from tf2_yolov4.model import YOLOv4\n",
    "\n",
    "from app.tools import draw_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure camera resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible image shapes for NOVIGA webcam\n",
    "WIDTH, HEIGHT = [(640, 360), (640, 480), (800, 600), (1280, 720), (1280, 960)][1]\n",
    "WIDTH, HEIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure CNN input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WIDTH_CNN, HEIGHT_CNN =  32 * 16, 32 * 12 # (Good enough+)\n",
    "WIDTH_CNN, HEIGHT_CNN =  32 * 8, 32 * 6 # (Good enough)\n",
    "#WIDTH_CNN, HEIGHT_CNN =  WIDTH, HEIGHT\n",
    "WIDTH_CNN, HEIGHT_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load YOLOv4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_objects = 20\n",
    "\n",
    "model = YOLOv4(\n",
    "    input_shape=(HEIGHT_CNN, WIDTH_CNN, 3),\n",
    "    anchors=YOLOV4_ANCHORS,\n",
    "    num_classes=80,\n",
    "    training=False,\n",
    "    yolo_max_boxes=max_objects,\n",
    "    yolo_iou_threshold=0.5,\n",
    "    yolo_score_threshold=0.6,\n",
    ")\n",
    "\n",
    "model.load_weights(\"../binaries/yolov4.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO classes. Ref https://gist.github.com/AruniRC/7b3dadd004da04c80198557db5da4bda\n",
    "CLASSES = [\n",
    "    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "    'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect objects from an image file (jpg, png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rad raw image\n",
    "image_bgr_raw = cv2.imread('../images/dip3.png')\n",
    "# resize image to expected CNN input\n",
    "image_resized = tf.image.resize(image_bgr_raw, (HEIGHT_CNN, WIDTH_CNN))\n",
    "# Add extra dimention and normalize pixel values (/255)\n",
    "images_array = tf.expand_dims(image_resized, axis=0) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect objects\n",
    "boxes, scores, classes, valid_detections = model.predict(images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create texts fields containing label and scores for every object detected\n",
    "texts = ['{} {:.2%}'.format(CLASSES[classes[0].astype(int)[_]], scores.round(3)[0][_]) for _ in range(classes.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add boxes and text based on model output\n",
    "new_img = draw_boxes(\n",
    "    img=image_bgr_raw,\n",
    "    rec_coordinates=boxes[0],\n",
    "    texts=texts,\n",
    "    colors=None, relative_coordinates=True,\n",
    "    rec_thickness=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot raw image\n",
    "image_rgb_raw = cv2.cvtColor(image_bgr_raw, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image_rgb_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image with detected objects\n",
    "new_img_rgb = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(new_img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenCV to show both images\n",
    "cv2.imshow('Raw image', image_bgr_raw)\n",
    "cv2.imshow('Detected objects in image', new_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect from streaming video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, WIDTH)\n",
    "cap.set(4, HEIGHT)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, bgr_frame_i = cap.read()\n",
    "    \n",
    "    # convert BGR to RGB\n",
    "    rgb_frame_i = cv2.cvtColor(bgr_frame_i, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize image to match YOLOv4 input\n",
    "    image_resized = tf.image.resize(bgr_frame_i, (HEIGHT_CNN, WIDTH_CNN))\n",
    "    \n",
    "    # Expand array dimension by 1 axis and nomarlize the array (/255)\n",
    "    frame_i = tf.expand_dims(tf.cast(image_resized, tf.float32), axis=0) / 255.0\n",
    "\n",
    "    # model predictions\n",
    "    boxes_i, scores_i, classes_i, valid_detections_i = model.predict(frame_i)\n",
    "    \n",
    "    # create text fields containing label and score\n",
    "    texts_i = ['{} {:.2%}'.format(CLASSES[classes_i[0].astype(int)[_]], scores_i.round(3)[0][_]) for _ in range(classes_i.shape[1])]\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    new_img = draw_boxes(\n",
    "        img=bgr_frame_i,\n",
    "        rec_coordinates=boxes_i[0],\n",
    "        texts=texts_i,\n",
    "        relative_coordinates=True)\n",
    "\n",
    "    cv2.imshow('Raw Image', bgr_frame_i)\n",
    "    cv2.imshow('New Image', new_img)\n",
    "\n",
    "    #Waits for a user input to quit the application\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "print('We reached the end...')\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov4-tf",
   "language": "python",
   "name": "yolov4-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
